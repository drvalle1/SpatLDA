rm(list=ls(all=TRUE))
library('gtools')
set.seed(1)
#get functions
setwd('U:\\GIT_models\\SpatLDA')
source('SpatLDA aux functions.R')
#get data
setwd('U:\\GIT_models\\SpatLDA\\fake data')
dat0=dat=read.csv('fake data1.csv',as.is=T)
#potential documents
coord.plot=expand.grid(x=seq(from=0,to=1000,by=200),
y=seq(from=0,to=1000,by=200))
nplot=nrow(coord.plot)
#useful stuff
nclust=3
ngibbs=10000
nburn=ngibbs/2
#priors
gamma.theta=0.1
gamma.phi=0.1
#useful stuff
ngrid=nrow(dat)
ind=grep('spp',colnames(dat))
nomes.spp=colnames(dat)[ind]
tmp1=as.numeric(gsub('spp','',nomes.spp))
nspp=max(tmp1)
#get distances
dist1=matrix(NA,ngrid,nplot)
for (i in 1:nplot){
x2=(dat$xbin-coord.plot$x[i])^2
y2=(dat$ybin-coord.plot$y[i])^2
dist1[,i]=sqrt(x2+y2)
}
#initial values for parameters
theta=matrix(1/nclust,nplot,nclust)
phi=matrix(1/nspp,nclust,nspp)
sig2=100
delta=get.delta(sig2=sig2,dist1=dist1)
#initial values for cluster and plot membership
array.gskp=array(0,dim=c(ngrid,nspp,nclust,nplot))
nbins=nclust*nplot
for (i in 1:ngrid){
for (j in 1:nspp){
tmp=dat[i,paste0('spp',j)]
if (tmp>0){
tmp1=rmultinom(1,size=tmp,prob=rep(1/nbins,nbins))
array.gskp[i,j,,]=matrix(tmp1,nclust,nplot)
}
}
}
# teste=apply(array.gskp,c(1,2),sum)
# unique(teste-dat[,paste0('spp',1:nspp)])
#MH stuff
jump.sd=1
accept1=0
nchange.jump=50
#to store outcomes from gibbs sampler
theta.out=matrix(NA,ngibbs,nclust*nplot)
phi.out=matrix(NA,ngibbs,nclust*nspp)
sig2.out=matrix(NA,ngibbs,1)
llk=rep(NA,ngibbs)
#run gibbs sampler
options(warn=2)
for (i in 1:ngibbs){
print(i)
#sample clust.id
for (s in 1:nspp){
array.gkp=array.gskp[,s,,]
array.gskp[,s,,]=sample.clust.id(theta=theta,phi=phi[,s],nplot=nplot,
array.gkp=array.gkp)
}
#sample plot.id
for (s in 1:nspp){
array.gkp=array.gskp[,s,,]
array.gskp[,s,,]=sample.plot.id(theta=theta,delta=delta,array.gkp=array.gkp,
ngrid=ngrid,nclust=nclust)
}
#sample theta
theta=sample.theta(array.gskp=array.gskp,nplot=nplot,nclust=nclust,gamma1.theta=gamma.theta)
# theta=theta.true
#sample phi
phi=sample.phi(array.gskp=array.gskp,gamma1.phi=gamma.phi,nclust=nclust,nspp=nspp)
# phi=phi.true
#sample sig2
tmp=sample.sig2(dist1=dist1,sig2=sig2,theta=theta,jump.sd=jump.sd,
ngrid=ngrid,nclust=nclust,array.gskp=array.gskp)
accept1=accept1+tmp$accept1
sig2=tmp$sig2
# sig2=sig2.true
delta=get.delta(sig2=sig2,dist1=dist1)
#adapt MH
if (i%%nchange.jump==0 & i<nburn){
if (accept1/nchange.jump < 0.1) jump.sd=jump.sd*0.5
if (accept1/nchange.jump > 0.6) jump.sd=jump.sd*2
accept1=0
}
#llk
llk[i]=get.llk(dat=dat,delta=delta,theta=theta,phi=phi,
ngrid=ngrid,nspp=nspp,nomes.spp=nomes.spp)
#store results
theta.out[i,]=theta
phi.out[i,]=phi
sig2.out[i]=sig2
}
plot(llk,type='l')
plot(sig2.out,type='l')
#get estimated values
theta.estim=theta
phi.estim=phi
delta.estim=delta
sig2.estim=sig2
library('ggplot2')
set.seed(3)
#trees
ntrees=10000
coord=data.frame(x=runif(ntrees,min=0,max=1000),
y=runif(ntrees,min=0,max=1000))
#documents
ndoc=3
coord.doc=data.frame(x=c(200,600,800),
y=c(200,400,800))
plot(y~x,data=coord)
points(y~x,data=coord.doc,col='red',pch=19)
#theta for each doc
nclust=3
theta=matrix(c(0.05,0.05,0.9,
0.05,0.9,0.05,
0.8,0.1,0.1),ndoc,nclust,byrow=T)
theta.true=theta
# apply(theta,1,sum)
#phi for each cluster
nspp=50
tmp=rbeta(nspp*nclust,0.1,0.1)
ind=sample(1:(nspp*nclust),size=25)
tmp[ind]=4
tmp1=matrix(tmp,nclust,nspp)
phi=tmp1/apply(tmp1,1,sum)
phi.true=phi
# head(round(phi[,1:10],3))
# hist(phi[5,])
#get distance from each document to each tree
dist1=matrix(NA,ntrees,ndoc)
for (i in 1:ndoc){
x2=(coord$x-coord.doc$x[i])^2
y2=(coord$y-coord.doc$y[i])^2
dist1[,i]=sqrt(x2+y2)
}
#get cluster membership for each tree
sig2=sig2.true=20
for (i in 1:ntrees){
#which document?
prob=exp(-(1/(2*sig2))*dist1[i,])
tmp=rmultinom(1,size=1,prob=prob/sum(prob))
ind=which(tmp==1)
coord$omega[i]=ind
#which cluster?
tmp=rmultinom(1,size=1,prob=theta[ind,])
ind=which(tmp==1)
coord$psi[i]=ind
#which species?
tmp=rmultinom(1,size=1,prob=phi[ind,])
ind=which(tmp==1)
coord$spp[i]=ind
}
#spatial distribution of communities
plot(y~x,data=coord,col=coord$psi,pch=19)
plot(y~x,data=coord,col=coord$omega,pch=19)
#export results
setwd('U:\\GIT_models\\SpatLDA\\fake data')
fim=matrix(NA,nclust,nclust)
for (i in 1:nclust){
for (j in 1:nclust){
tmp=cbind(phi.true[i,],phi.estim[j,])
fim[i,j]=cor(tmp)[1,2]
}
}
fim
ordem=c(3,1,2)
theta.estim1=theta.estim[,ordem]
rango=range(c(theta.true,theta.estim1))
plot(theta.true,theta.estim1,xlim=rango,ylim=rango)
lines(rango,rango,col='red')
phi.estim1=phi.estim[ordem,]
rango=range(c(phi.true,phi.estim1))
plot(phi.true,phi.estim1,xlim=rango,ylim=rango)
lines(rango,rango,col='red')
fim
ordem=c(3,2,1)
phi.estim1=phi.estim[ordem,]
rango=range(c(phi.true,phi.estim1))
plot(phi.true,phi.estim1,xlim=rango,ylim=rango)
lines(rango,rango,col='red')
coord=expand.grid(x=seq(from=0,to=1000,by=10),
y=seq(from=0,to=1000,by=10))
ncoord=nrow(coord)
#get distances
nplot=nrow(coord.plot)
dist1=matrix(NA,ncoord,nplot)
for (i in 1:nplot){
x2=(coord$x-coord.plot$x[i])^2
y2=(coord$y-coord.plot$y[i])^2
dist1[,i]=sqrt(x2+y2)
}
#calculate probabilities
res=matrix(NA,ncoord,nclust)
for (i in 1:ncoord){
tmp=exp(-(1/(2*sig2.estim))*dist1[i,])
delta=tmp/sum(tmp)
for (j in 1:nclust){
res[i,j]=sum(theta.estim[,j]*delta)
}
}
#create final data.frame with prob for each cluster
colnames(res)=paste0('c',1:nclust)
res1=as.data.frame(res)
coord1=cbind(coord,res1)
#plot results
library(gridExtra)
library(grid)
p1=ggplot() +
geom_tile(data = coord1, alpha = 0.8,aes(x = x, y = y,fill = c1)) +
scale_fill_gradient2(low = "cyan", mid = "red",high='purple',limits=c(0,1),midpoint=0.5)
p2=ggplot() +
geom_tile(data = coord1, alpha = 0.8,aes(x = x, y = y,fill = c2)) +
scale_fill_gradient2(low = "cyan", mid = "red",high='purple',limits=c(0,1),midpoint=0.5)
p3=ggplot() +
geom_tile(data = coord1, alpha = 0.8,aes(x = x, y = y,fill = c3)) +
scale_fill_gradient2(low = "cyan", mid = "red",high='purple',limits=c(0,1),midpoint=0.5)
grid.arrange(p1, p2, p3,nrow = 1)
coord=expand.grid(x=seq(from=0,to=1000,by=10),
y=seq(from=0,to=1000,by=10))
ncoord=nrow(coord)
#get distances
dist1=matrix(NA,ncoord,ndoc)
for (i in 1:ndoc){
x2=(coord$x-coord.doc$x[i])^2
y2=(coord$y-coord.doc$y[i])^2
dist1[,i]=sqrt(x2+y2)
}
#calculate probabilities
res=matrix(NA,ncoord,nclust)
for (i in 1:ncoord){
tmp=exp(-(1/(2*sig2))*dist1[i,])
delta=tmp/sum(tmp)
for (j in 1:nclust){
res[i,j]=sum(theta[,j]*delta)
}
}
#create final data.frame with prob for each cluster
colnames(res)=paste0('c',1:nclust)
res1=as.data.frame(res)
coord1=cbind(coord,res1)
#plot results
library(gridExtra)
library(grid)
p1=ggplot() +
geom_tile(data = coord1, alpha = 0.8,aes(x = x, y = y,fill = c1)) +
scale_fill_gradient2(low = "cyan", mid = "red",high='purple',limits=c(0,1),midpoint=0.5)
p2=ggplot() +
geom_tile(data = coord1, alpha = 0.8,aes(x = x, y = y,fill = c2)) +
scale_fill_gradient2(low = "cyan", mid = "red",high='purple',limits=c(0,1),midpoint=0.5)
p3=ggplot() +
geom_tile(data = coord1, alpha = 0.8,aes(x = x, y = y,fill = c3)) +
scale_fill_gradient2(low = "cyan", mid = "red",high='purple',limits=c(0,1),midpoint=0.5)
grid.arrange(p1, p2, p3,nrow = 1)
